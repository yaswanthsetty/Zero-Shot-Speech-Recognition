# Zero-Shot Speech Recognition Research

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/release/python-3100/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-orange.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

A comprehensive research project implementing zero-shot spoken language identification using phonological features and deep learning techniques.

## ï¿½ Recent Updates (September 2025)

- âš¡ **8x Performance Boost**: Implemented batch processing for feature extraction
- ğŸ”§ **Fixed Dataset Loading**: Updated for latest HuggingFace datasets API
- ğŸ›¡ï¸ **Enhanced Reliability**: Added robust error handling and fallback mechanisms
- ğŸ“Š **Better Progress Tracking**: Real-time processing updates
- ğŸ **Type Safety**: Fixed all type annotations and linting issues
- ğŸ”„ **Automatic Fallbacks**: Synthetic data generation when real datasets fail

## ï¿½ğŸ¯ Project Overview

This repository contains a state-of-the-art implementation of zero-shot language identification that can recognize spoken languages without prior training on those specific languages. The system leverages cross-linguistic phonological features to enable transfer learning across language families.

## ğŸ—ï¸ How It Works

```
Speech Audio â†’ Audio Features â†’ Phonological Space â†’ Language Match
```

The system converts speech into phonological features (sound patterns) that are similar across related languages, enabling zero-shot transfer.

## ğŸ“ Repository Structure

```
Zero-Shot-Speech-Recognition/
â”œâ”€â”€ zero-shot-lid/              # ğŸ¯ Main project (detailed docs inside)
â”‚   â”œâ”€â”€ src/                    # Source code modules
â”‚   â”œâ”€â”€ main.py                 # Run the complete system
â”‚   â”œâ”€â”€ requirements.txt        # Dependencies
â”‚   â””â”€â”€ README.md              # ğŸ“– Detailed technical documentation
â”œâ”€â”€ models/                     # Generated model files
â””â”€â”€ README.md                  # ğŸ‘ˆ This overview file
```

**ğŸ“– For detailed technical documentation, installation instructions, and API reference, see [`zero-shot-lid/README.md`](zero-shot-lid/README.md)**

## ğŸš€ Quick Start

```bash
# Clone and run
git clone https://github.com/yaswanthsetty/Zero-Shot-Speech-Recognition.git
cd Zero-Shot-Speech-Recognition/zero-shot-lid
pip install -r requirements.txt
python main.py
```

**ğŸ”§ For detailed setup instructions, troubleshooting, and advanced usage, see [`zero-shot-lid/README.md`](zero-shot-lid/README.md)**

## âœ¨ Key Capabilities

- **ï¿½ Zero-Shot Recognition**: Identify languages never seen during training
- **âš¡ High Performance**: 8x faster processing with batch optimization
- **ğŸ›¡ï¸ Robust & Reliable**: Automatic fallbacks and error handling
- **ï¿½ Research Ready**: Complete pipeline for academic and industry use
- **ğŸ“Š Comprehensive**: Supports 20 languages (15 training + 5 testing)

## ï¿½ Performance Highlights

| Metric | Value |
|--------|-------|
| **Languages** | 20 total (15 train + 5 test) |
| **Model Size** | 667K parameters (lightweight) |
| **Speed** | 8x faster (batch processing) |
| **Memory** | ~2GB RAM |
| **Expected Accuracy** | 45-80% (depending on language similarity) |

**ğŸ¯ Recent Updates**: 8x performance boost, fixed dataset loading, enhanced reliability

## ğŸ”¬ Research Applications

This implementation is suitable for:
- **Academic Research**: Cross-lingual transfer learning studies
- **Industry Applications**: Multilingual speech systems
- **Educational Use**: Understanding phonological features in ML
- **Baseline Development**: Comparison with other approaches



## ï¿½ Research Applications

- **ğŸ“ Academic Research**: Cross-lingual transfer learning studies
- **ğŸ¢ Industry Applications**: Multilingual speech systems
- **ğŸ“š Educational**: Understanding phonological features in ML
- **ğŸ“Š Benchmarking**: Baseline for other approaches

## ğŸ¤ Contributing

Contributions welcome! See [`zero-shot-lid/CONTRIBUTING.md`](zero-shot-lid/CONTRIBUTING.md) for guidelines.

## ï¿½ Documentation

- **ğŸ“‹ Detailed Setup**: [`zero-shot-lid/README.md`](zero-shot-lid/README.md)
- **ğŸ”§ Technical Details**: Architecture, dependencies, configuration
- **ğŸš¨ Troubleshooting**: Common issues and solutions
- **ğŸ“š API Reference**: Function and class documentation
- **ğŸ§ª Experiments**: Performance analysis and research insights

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](zero-shot-lid/LICENSE) file for details.

## ï¿½ License

MIT License - see [LICENSE](zero-shot-lid/LICENSE) for details.

## ğŸ“ Contact

- **ğŸ› Issues**: [GitHub Issues](https://github.com/yaswanthsetty/Zero-Shot-Speech-Recognition/issues)
- **ğŸ’¬ Discussions**: [GitHub Discussions](https://github.com/yaswanthsetty/Zero-Shot-Speech-Recognition/discussions)
- **ğŸ‘¤ Author**: [Yaswanth Setty](https://github.com/yaswanthsetty)

---

<div align="center">

**ğŸŒ Zero-shot cross-lingual understanding through phonological intelligence ğŸ¤**

[ğŸ“– Detailed Documentation](zero-shot-lid/README.md) â€¢ [ğŸš€ Quick Start](#-quick-start) â€¢ [ğŸ¤ Contributing](#-contributing)

</div>